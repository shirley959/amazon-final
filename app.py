import streamlit as st
import requests
import time
import base64
from openai import OpenAI
from PIL import Image, ImageDraw, ImageFont
from io import BytesIO

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="Amazon AI Studio (Direct Flux)", layout="wide")

# --- 2. å®‰å…¨é—¨ç¦ ---
def check_password():
    if "password_correct" not in st.session_state:
        st.session_state.password_correct = False
    if not st.session_state.password_correct:
        pwd = st.text_input("ğŸ”’ è¯·è¾“å…¥è®¿é—®å¯†ç ", type="password")
        if st.button("ç™»å½•"):
            if pwd == st.secrets["APP_PASSWORD"]:
                st.session_state.password_correct = True
                st.rerun()
            else:
                st.error("âŒ å¯†ç é”™è¯¯")
        st.stop()
check_password()

# --- 3. è¯»å–åå° Key ---
openai_key = st.secrets["OPENAI_KEY"]
fal_key = st.secrets["FAL_KEY"]

# --- 4. ä¾§è¾¹æ é…ç½® ---
with st.sidebar:
    st.success("âœ… éªŒè¯é€šè¿‡")
    st.info("âš ï¸ å½“å‰æ¨¡å¼ï¼šç›´æ¥èåˆ (è·³è¿‡æŠ å›¾)")
    # é»˜è®¤å¡«å…¥ä½ æŠ¥é”™é‡Œçš„è¿™ä¸ªåŸŸå
    base_url = st.text_input("ä¸­è½¬æ¥å£åœ°å€", value="https://api.vectorengine.ai") 
    
    st.markdown("---")
    st.header("ğŸ¨ å‚æ•°è®¾ç½®")
    # å…³é”®å‚æ•°ï¼šæ§åˆ¶ AI æ”¹å›¾çš„å¹…åº¦
    strength = st.slider("äº§å“ä¿ç•™åº¦ (Strength)", 0.5, 1.0, 0.75, 
                         help="0.75æ˜¯æœ€ä½³å¹³è¡¡ç‚¹ï¼šæ—¢èƒ½ä¿ç•™äº§å“ï¼Œåˆèƒ½èåˆèƒŒæ™¯ã€‚")
    
    mode = st.radio("å°ºå¯¸", ("Listing (1024x1024)", "A+ Banner (1536x512)"))
    if "Listing" in mode: w, h = 1024, 1024
    else: w, h = 1536, 512

# --- 5. æ ¸å¿ƒå·¥å…·å‡½æ•° ---

def image_to_base64(image):
    buffered = BytesIO()
    image.convert("RGB").save(buffered, format="JPEG")
    img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
    return f"data:image/jpeg;base64,{img_str}"

def fal_request_relay(api_key, base_url, model, data):
    base_url = base_url.rstrip("/")
    submit_url = f"{base_url}/{model}"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    
    try:
        resp = requests.post(submit_url, json=data, headers=headers)
        resp.raise_for_status() # å¦‚æœæŠ¥é”™403è¿™é‡Œä¼šæŠ›å‡ºå¼‚å¸¸
        res_json = resp.json()
    except Exception as e:
        st.error(f"æäº¤ä»»åŠ¡å¤±è´¥: {e}")
        return None

    # è·å–ç»“æœæŸ¥è¯¢åœ°å€
    if "response_url" in res_json:
        target_path = res_json["response_url"].split("queue.fal.run")[-1]
        poll_url = f"{base_url}{target_path}"
    elif "images" in res_json:
        # æœ‰çš„ä¸­è½¬ç«™ç§’å›ç»“æœ
        return res_json["images"][0]["url"]
    else:
        st.error("ä¸­è½¬ç«™è¿”å›æ ¼å¼å¼‚å¸¸")
        return None

    # è½®è¯¢
    placeholder = st.empty()
    for i in range(40): 
        placeholder.text(f"â³ AI æ­£åœ¨ç»˜å›¾... ({i*2}s)")
        time.sleep(2)
        try:
            poll_resp = requests.get(poll_url, headers=headers)
            if poll_resp.status_code == 200:
                poll_data = poll_resp.json()
                if "images" in poll_data:
                    placeholder.empty()
                    return poll_data["images"][0]["url"]
        except:
            pass
    return None

def generate_scene_direct(api_key, base_url, original_img, prompt, strength, w, h):
    """ç›´æ¥è°ƒç”¨ Flux å›¾ç”Ÿå›¾ (é¿å¼€ä¸æ”¯æŒçš„ Birefnet)"""
    base64_img = image_to_base64(original_img)
    
    # æ—¢ç„¶æ˜¯å›¾ç”Ÿå›¾ï¼ŒPrompt å¿…é¡»å¼ºè°ƒä¿ç•™äº§å“
    full_prompt = f"{prompt}. The main product in the image stays unchanged, only the background changes to the described scene. High quality, 8k."
    
    data = {
        "prompt": full_prompt,
        "image_url": base64_img,
        "strength": strength, # è¿™é‡Œç”¨ Strength æ¥æ§åˆ¶èåˆ
        "image_size": {"width": w, "height": h},
        "num_inference_steps": 30,
        "guidance_scale": 3.5
    }
    # ä½¿ç”¨ä½ æ”¯æŒåˆ—è¡¨é‡Œçš„æ¨¡å‹
    return fal_request_relay(api_key, base_url, "fal-ai/flux-1/dev/image-to-image", data)

def get_gpt_instruction(api_key, text, product_name):
    client = OpenAI(api_key=api_key)
    prompt = f"Role: Amazon Art Director. Product: {product_name}. Input: {text}. Output: TITLE | SUBTITLE | PROMPT"
    try:
        res = client.chat.completions.create(
            model="gpt-4o", messages=[{"role": "user", "content": prompt}]
        )
        return res.choices[0].message.content.split("|")
    except:
        return ["Feature", text, f"Photo of {product_name}, {text}"]

def add_text(image, title, subtitle):
    draw = ImageDraw.Draw(image)
    w, h = image.size
    draw.rectangle([(0, h - h//5), (w, h)], fill=(0, 0, 0, 180))
    try: font = ImageFont.truetype("arial.ttf", int(h/20))
    except: font = ImageFont.load_default()
    draw.text((30, h - h//5 + 20), title.strip(), fill="white", font=font)
    draw.text((30, h - h//5 + 60), subtitle.strip(), fill="#CCCCCC", font=font)
    return image

# --- 6. ä¸»ç•Œé¢ ---
st.title("ğŸ›’ Amazon AI Studio (Direct)")
st.caption("é€‚é… Vector Engine èšåˆå¹³å° | Flux å›¾ç”Ÿå›¾æ¨¡å¼")

col1, col2 = st.columns([1, 1])
with col1:
    product_name = st.text_input("äº§å“åç§°", "Product")
    uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼ äº§å“å›¾ (æ¨èç™½åº•)", type=["jpg", "png", "jpeg"])
    texts = [st.text_input(f"å–ç‚¹ {i+1}", key=i) for i in range(1)]
    btn = st.button("ğŸš€ å¼€å§‹ç”Ÿæˆ", type="primary")

with col2:
    if btn and uploaded_file and base_url:
        st.info("ğŸ”„ æ­£åœ¨å¤„ç†å›¾ç‰‡...")
        original_img = Image.open(uploaded_file)
        
        # ä¸å†è°ƒç”¨ remove_bgï¼Œç›´æ¥è¿›å…¥ Flux ç”Ÿæˆ
        for i, text in enumerate([t for t in texts if t]):
            info = get_gpt_instruction(openai_key, text, product_name)
            if len(info)<3: info=["Title","Sub",text]
            
            st.info(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆåœºæ™¯ (Prompt: {info[2]})...")
            
            # è°ƒç”¨ Flux å›¾ç”Ÿå›¾
            final_url = generate_scene_direct(fal_key, base_url, original_img, info[2], strength, w, h)
            
            if final_url:
                img_data = requests.get(final_url).content
                final_result = add_text(Image.open(BytesIO(img_data)), info[0], info[1])
                st.image(final_result, caption="æœ€ç»ˆç»“æœ", use_column_width=True)
            else:
                st.error("ç”Ÿæˆå¤±è´¥ï¼Œå¯èƒ½æ˜¯ Strength å‚æ•°å¤ªé«˜æˆ– Prompt è¿è§„")