import streamlit as st
import requests
import time
import base64
from openai import OpenAI
from PIL import Image, ImageDraw, ImageFont
from io import BytesIO

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="Amazon AI Studio (Ultimate Relay)", layout="wide")

# --- 2. å®‰å…¨é—¨ç¦ ---
def check_password():
    if "password_correct" not in st.session_state:
        st.session_state.password_correct = False
    if not st.session_state.password_correct:
        pwd = st.text_input("ğŸ”’ è¯·è¾“å…¥è®¿é—®å¯†ç ", type="password")
        if st.button("ç™»å½•"):
            if pwd == st.secrets["APP_PASSWORD"]:
                st.session_state.password_correct = True
                st.rerun()
            else:
                st.error("âŒ å¯†ç é”™è¯¯")
        st.stop()
check_password()

# --- 3. è¯»å–åå° Key ---
openai_key = st.secrets["OPENAI_KEY"]
fal_key = st.secrets["FAL_KEY"]

# --- 4. ä¾§è¾¹æ é…ç½® ---
with st.sidebar:
    st.success("âœ… éªŒè¯é€šè¿‡")
    st.warning("ğŸ‘‡ å¿…å¡«ï¼šèšåˆå¹³å°åŸŸå")
    # æ¯”å¦‚ https://api.openai-hk.com
    base_url = st.text_input("ä¸­è½¬æ¥å£åœ°å€ (BASE_URL)", value="https://api.openai-hk.com") 
    
    st.markdown("---")
    st.header("ğŸ–¼ï¸ ç”Ÿæˆè®¾ç½®")
    mode = st.radio("é€‰æ‹©æ¨¡å¼", ("Listing Images (ä¸»å›¾/é™„å›¾)", "A+ Content (å“ç‰Œæ¨ªå¹…)"))
    
    if "Listing" in mode:
        width, height = 1024, 1024
    else:
        width, height = 1536, 512

# --- 5. æ ¸å¿ƒå·¥å…·å‡½æ•° (é€‚é…ä¸­è½¬ç«™) ---

def image_to_base64(image):
    buffered = BytesIO()
    image.convert("RGB").save(buffered, format="JPEG")
    img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
    return f"data:image/jpeg;base64,{img_str}"

def fal_request_relay(api_key, base_url, model, data):
    base_url = base_url.rstrip("/")
    submit_url = f"{base_url}/{model}"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    
    try:
        resp = requests.post(submit_url, json=data, headers=headers)
        resp.raise_for_status()
        res_json = resp.json()
    except Exception as e:
        st.error(f"æäº¤ä»»åŠ¡å¤±è´¥: {e}")
        return None

    if "response_url" in res_json:
        # æ›¿æ¢ä¸ºä¸­è½¬åŸŸåè¿›è¡ŒæŸ¥è¯¢
        target_path = res_json["response_url"].split("queue.fal.run")[-1]
        poll_url = f"{base_url}{target_path}"
    else:
        # æœ‰äº›ä¸­è½¬ç«™ç›´æ¥è¿”å›ç»“æœï¼Œåšä¸ªå…¼å®¹
        if "images" in res_json: return res_json["images"][0]["url"]
        st.error("ä¸­è½¬ç«™æœªè¿”å›æŸ¥è¯¢åœ°å€")
        return None

    placeholder = st.empty()
    for i in range(60): 
        placeholder.text(f"â³ AI æ­£åœ¨ç»˜å›¾... ({i*2}s)")
        time.sleep(2)
        try:
            poll_resp = requests.get(poll_url, headers=headers)
            if poll_resp.status_code == 200:
                poll_data = poll_resp.json()
                if "images" in poll_data:
                    placeholder.empty()
                    return poll_data["images"][0]["url"]
        except:
            pass
    return None

def step_1_remove_bg(api_key, base_url, original_image):
    # æ­¥éª¤1ï¼šè°ƒç”¨ BirefNet æŠ å›¾
    base64_str = image_to_base64(original_image)
    data = {"image_url": base64_str} 
    return fal_request_relay(api_key, base_url, "fal-ai/birefnet", data)

def step_2_generate_scene(api_key, base_url, clean_img_url, prompt, w, h):
    # æ­¥éª¤2ï¼šFlux åœºæ™¯èåˆ
    data = {
        "prompt": f"{prompt}. Product integrated naturally. High quality, 8k.",
        "image_url": clean_img_url, 
        "strength": 0.95, 
        "image_size": {"width": w, "height": h},
        "num_inference_steps": 28,
        "guidance_scale": 3.5
    }
    return fal_request_relay(api_key, base_url, "fal-ai/flux-1/dev/image-to-image", data)

def get_gpt_instruction(api_key, text, product_name, mode):
    client = OpenAI(api_key=api_key)
    prompt = f"Role: Amazon Art Director. Product: {product_name}. Input: {text}. Mode: {mode}. Output: TITLE | SUBTITLE | PROMPT"
    try:
        res = client.chat.completions.create(
            model="gpt-4o", messages=[{"role": "user", "content": prompt}]
        )
        return res.choices[0].message.content.split("|")
    except:
        return ["Feature", text, f"Photo of {product_name}"]

def add_text(image, title, subtitle):
    draw = ImageDraw.Draw(image)
    w, h = image.size
    draw.rectangle([(0, h - h//5), (w, h)], fill=(0, 0, 0, 180))
    try: font = ImageFont.truetype("arial.ttf", int(h/20))
    except: font = ImageFont.load_default()
    draw.text((30, h - h//5 + 20), title.strip(), fill="white", font=font)
    draw.text((30, h - h//5 + 60), subtitle.strip(), fill="#CCCCCC", font=font)
    return image

# --- 6. ä¸»ç•Œé¢ ---
st.title("ğŸ›’ Amazon AI Studio (Relay)")

col1, col2 = st.columns([1, 1])
with col1:
    product_name = st.text_input("äº§å“åç§°", "Product")
    uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼ ä»»æ„èƒŒæ™¯å›¾", type=["jpg", "png", "jpeg"])
    texts = [st.text_input(f"å–ç‚¹ {i+1}", key=i) for i in range(1)] # æ¼”ç¤ºåªç”Ÿæˆ1å¼ 
    btn = st.button("ğŸš€ å¼€å§‹ç”Ÿæˆ", type="primary")

with col2:
    if btn and uploaded_file and base_url:
        st.info("âœ‚ï¸ æ­£åœ¨æ™ºèƒ½æŠ å›¾...")
        original_img = Image.open(uploaded_file)
        clean_url = step_1_remove_bg(fal_key, base_url, original_img)
        
        if clean_url:
            st.image(clean_url, width=150, caption="æŠ å›¾æˆåŠŸ")
            for i, text in enumerate([t for t in texts if t]):
                st.info(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆåœºæ™¯å›¾...")
                info = get_gpt_instruction(openai_key, text, product_name, mode)
                if len(info)<3: info=["Title","Sub",text]
                
                final_url = step_2_generate_scene(fal_key, base_url, clean_url, info[2], width, height)
                if final_url:
                    img_data = requests.get(final_url).content
                    final_result = add_text(Image.open(BytesIO(img_data)), info[0], info[1])
                    st.image(final_result, caption="æœ€ç»ˆç»“æœ", use_column_width=True)
        else:
            st.error("æŠ å›¾å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸­è½¬ç«™æ˜¯å¦æ”¯æŒ fal-ai/birefnet")